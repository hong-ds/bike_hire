{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de145118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from matplotlib.dates import DateFormatter\n",
    "import matplotlib as mpl\n",
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "import sklearn.metrics as metrics\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import xgboost as xgb\n",
    "from skopt import BayesSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68dc880a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = \"../data\"\n",
    "RAW_DATA_PATH = f\"{BASE_PATH}/raw\"\n",
    "TMP_PATH = f\"{BASE_PATH}/tmp\"\n",
    "FILE_PATTERN = RAW_DATA_PATH + \"/*/OD*\"\n",
    "STATION_PATTERN = RAW_DATA_PATH + \"/*/Stations*\"\n",
    "START_STATION = 6184\n",
    "END_STATION = 6015\n",
    "START_DATE = \"2014-04-15\"\n",
    "END_DATE = \"2017-11-15\"\n",
    "THOUSANDS_SYMBOL = \" (000s)\"\n",
    "USE_CACHE = True\n",
    "NUM_CLUSTER = 12\n",
    "MINIMUM_TRIPS_PAIRWISE = 800\n",
    "FORECAST_START = \"2017-09-04\"\n",
    "FORECAST_END = \"2017-09-10\"\n",
    "ITERATIONS = 1 # 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72d7e785",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path_pattern: str, parse_dates=False) -> pd.DataFrame:\n",
    "    filepath = [pd.read_csv(name, parse_dates=parse_dates) for name in glob.glob(path_pattern)]\n",
    "    df = pd.concat(filepath)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93454f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data(FILE_PATTERN, parse_dates=[\"start_date\", \"end_date\"])\n",
    "df = df.loc[\n",
    "        (df.start_date >= START_DATE) &\n",
    "        (df.end_date < END_DATE)\n",
    "    ].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b04cbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = pd.read_csv(f\"{TMP_PATH}/clean_stations.csv\")\n",
    "cluster = pd.read_csv(f\"{TMP_PATH}/station_cluster.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4965e11f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_station_code</th>\n",
       "      <th>name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6347</td>\n",
       "      <td>Métro St-Michel (Shaughnessy / St-Michel)</td>\n",
       "      <td>45.559199</td>\n",
       "      <td>-73.599658</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6219</td>\n",
       "      <td>de l'Hôtel-de-Ville / Roy</td>\n",
       "      <td>45.517333</td>\n",
       "      <td>-73.574436</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6312</td>\n",
       "      <td>de Kent / de la Côte-des-Neiges</td>\n",
       "      <td>45.501302</td>\n",
       "      <td>-73.633161</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6138</td>\n",
       "      <td>Gauthier / De Lorimier</td>\n",
       "      <td>45.531818</td>\n",
       "      <td>-73.565317</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6205</td>\n",
       "      <td>Milton / du Parc</td>\n",
       "      <td>45.509710</td>\n",
       "      <td>-73.573540</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_station_code                                       name   latitude  \\\n",
       "0                6347  Métro St-Michel (Shaughnessy / St-Michel)  45.559199   \n",
       "1                6219                  de l'Hôtel-de-Ville / Roy  45.517333   \n",
       "2                6312            de Kent / de la Côte-des-Neiges  45.501302   \n",
       "3                6138                     Gauthier / De Lorimier  45.531818   \n",
       "4                6205                           Milton / du Parc  45.509710   \n",
       "\n",
       "   longitude  cluster  \n",
       "0 -73.599658        4  \n",
       "1 -73.574436        5  \n",
       "2 -73.633161        6  \n",
       "3 -73.565317        8  \n",
       "4 -73.573540        1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations = stations.merge(cluster, on=\"code\")\n",
    "stations.rename({\"code\": \"start_station_code\"}, axis=1, inplace=True)\n",
    "stations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d090d4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = df.merge(stations[[\"start_station_code\", \"latitude\", \"longitude\", \"cluster\"]], on=\"start_station_code\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f0075e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date</th>\n",
       "      <th>start_station_code</th>\n",
       "      <th>end_date</th>\n",
       "      <th>end_station_code</th>\n",
       "      <th>duration_sec</th>\n",
       "      <th>is_member</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-08-01 00:00:00</td>\n",
       "      <td>6215</td>\n",
       "      <td>2014-08-01 00:11:00</td>\n",
       "      <td>6151</td>\n",
       "      <td>702</td>\n",
       "      <td>0</td>\n",
       "      <td>45.514914</td>\n",
       "      <td>-73.578243</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-08-01 00:03:00</td>\n",
       "      <td>6215</td>\n",
       "      <td>2014-08-01 00:16:00</td>\n",
       "      <td>6152</td>\n",
       "      <td>800</td>\n",
       "      <td>1</td>\n",
       "      <td>45.514914</td>\n",
       "      <td>-73.578243</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-08-01 00:09:00</td>\n",
       "      <td>6215</td>\n",
       "      <td>2014-08-01 00:12:00</td>\n",
       "      <td>6181</td>\n",
       "      <td>178</td>\n",
       "      <td>1</td>\n",
       "      <td>45.514914</td>\n",
       "      <td>-73.578243</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-08-01 06:15:00</td>\n",
       "      <td>6215</td>\n",
       "      <td>2014-08-01 06:19:00</td>\n",
       "      <td>6221</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>45.514914</td>\n",
       "      <td>-73.578243</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-08-01 06:49:00</td>\n",
       "      <td>6215</td>\n",
       "      <td>2014-08-01 06:57:00</td>\n",
       "      <td>6065</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>45.514914</td>\n",
       "      <td>-73.578243</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           start_date  start_station_code            end_date  \\\n",
       "0 2014-08-01 00:00:00                6215 2014-08-01 00:11:00   \n",
       "1 2014-08-01 00:03:00                6215 2014-08-01 00:16:00   \n",
       "2 2014-08-01 00:09:00                6215 2014-08-01 00:12:00   \n",
       "3 2014-08-01 06:15:00                6215 2014-08-01 06:19:00   \n",
       "4 2014-08-01 06:49:00                6215 2014-08-01 06:57:00   \n",
       "\n",
       "   end_station_code  duration_sec  is_member   latitude  longitude  cluster  \n",
       "0              6151           702          0  45.514914 -73.578243        5  \n",
       "1              6152           800          1  45.514914 -73.578243        5  \n",
       "2              6181           178          1  45.514914 -73.578243        5  \n",
       "3              6221           233          1  45.514914 -73.578243        5  \n",
       "4              6065           512          1  45.514914 -73.578243        5  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7a2c517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14806753, 9)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a8179f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_results(y_true, y_pred):\n",
    "    # Regression metrics\n",
    "    explained_variance=metrics.explained_variance_score(y_true, y_pred)\n",
    "    mean_absolute_error=metrics.mean_absolute_error(y_true, y_pred) \n",
    "    mse=metrics.mean_squared_error(y_true, y_pred) \n",
    "    mean_squared_log_error=metrics.mean_squared_log_error(y_true, y_pred)\n",
    "    median_absolute_error=metrics.median_absolute_error(y_true, y_pred)\n",
    "    r2=metrics.r2_score(y_true, y_pred)\n",
    "    print('explained_variance: ', round(explained_variance,4))    \n",
    "    print('mean_squared_log_error: ', round(mean_squared_log_error,4))\n",
    "    print('r2: ', round(r2,4))\n",
    "    print('MAE: ', round(mean_absolute_error,4))\n",
    "    print('MSE: ', round(mse,4))\n",
    "    print('RMSE: ', round(np.sqrt(mse),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69bb74d",
   "metadata": {},
   "source": [
    "# Prediction member only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89eb220a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df_member = combined_df.loc[combined_df.is_member == 1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e456397e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12302081, 9)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df_member.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256ef8f0",
   "metadata": {},
   "source": [
    "**Data Cleaning**: since our training unit should be number of trips between pairwise-stations per day, need to do some basic transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74a106cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df_member[\"start_date\"] = clean_df_member[\"start_date\"].dt.normalize()\n",
    "clean_df_member.drop([\"end_date\"], axis=1, inplace=True)\n",
    "clean_df_member = clean_df_member.groupby([\"start_date\", \"start_station_code\", \"end_station_code\"]).agg(\n",
    "    {\n",
    "        \"duration_sec\": np.mean, \n",
    "        \"is_member\": np.mean, \n",
    "        \"latitude\": max, \n",
    "        \"longitude\": max, \n",
    "        \"cluster\": [max, \"count\"]\n",
    "    }\n",
    ").reset_index()\n",
    "clean_df_member.columns = [\"start_date\", \"start_station_code\", \"end_station_code\", \"avg_duration\", \"is_member_ratio\", \"latitude\", \"longitude\", \"cluster\", \"num_trips\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e282903",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = clean_df_member.loc[clean_df_member.start_date <= '2017-07-30']\n",
    "test = clean_df_member.loc[clean_df_member.start_date > '2017-07-30']\n",
    "forecast = clean_df_member.loc[\n",
    "    (clean_df_member.start_date >= FORECAST_START) & \n",
    "    (clean_df_member.start_date <= FORECAST_END) &\n",
    "    (clean_df_member.start_station_code == START_STATION) &\n",
    "    (clean_df_member.end_station_code == END_STATION)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8014709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7874799, 9), (1404420, 9), (5, 9))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape, forecast.shape # tradition split train test, with the forecast set for the requirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56f61a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date</th>\n",
       "      <th>start_station_code</th>\n",
       "      <th>end_station_code</th>\n",
       "      <th>avg_duration</th>\n",
       "      <th>is_member_ratio</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>cluster</th>\n",
       "      <th>num_trips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017-09-04</td>\n",
       "      <td>6184.0</td>\n",
       "      <td>6015.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.524673</td>\n",
       "      <td>-73.58255</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-09-05</td>\n",
       "      <td>6184.0</td>\n",
       "      <td>6015.0</td>\n",
       "      <td>576.166667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.524673</td>\n",
       "      <td>-73.58255</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017-09-06</td>\n",
       "      <td>6184.0</td>\n",
       "      <td>6015.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.524673</td>\n",
       "      <td>-73.58255</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-09-07</td>\n",
       "      <td>6184.0</td>\n",
       "      <td>6015.0</td>\n",
       "      <td>810.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.524673</td>\n",
       "      <td>-73.58255</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-09-08</td>\n",
       "      <td>6184.0</td>\n",
       "      <td>6015.0</td>\n",
       "      <td>557.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.524673</td>\n",
       "      <td>-73.58255</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-09-09</td>\n",
       "      <td>6184.0</td>\n",
       "      <td>6015.0</td>\n",
       "      <td>525.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.524673</td>\n",
       "      <td>-73.58255</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-09-10</td>\n",
       "      <td>6184.0</td>\n",
       "      <td>6015.0</td>\n",
       "      <td>1374.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.524673</td>\n",
       "      <td>-73.58255</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  start_date  start_station_code  end_station_code  avg_duration  \\\n",
       "6 2017-09-04              6184.0            6015.0      0.000000   \n",
       "0 2017-09-05              6184.0            6015.0    576.166667   \n",
       "5 2017-09-06              6184.0            6015.0      0.000000   \n",
       "1 2017-09-07              6184.0            6015.0    810.500000   \n",
       "2 2017-09-08              6184.0            6015.0    557.333333   \n",
       "3 2017-09-09              6184.0            6015.0    525.333333   \n",
       "4 2017-09-10              6184.0            6015.0   1374.000000   \n",
       "\n",
       "   is_member_ratio   latitude  longitude  cluster  num_trips  \n",
       "6              0.0  45.524673  -73.58255      2.0        0.0  \n",
       "0              1.0  45.524673  -73.58255      2.0        6.0  \n",
       "5              0.0  45.524673  -73.58255      2.0        0.0  \n",
       "1              1.0  45.524673  -73.58255      2.0        2.0  \n",
       "2              1.0  45.524673  -73.58255      2.0        3.0  \n",
       "3              1.0  45.524673  -73.58255      2.0        3.0  \n",
       "4              1.0  45.524673  -73.58255      2.0        1.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_range = pd.date_range(start=FORECAST_START, end=FORECAST_END)\n",
    "missing_prediction = list(set(prediction_range) - set(forecast.start_date))\n",
    "\n",
    "# add back missing prediction\n",
    "forecast = pd.concat([forecast, pd.DataFrame({\n",
    "    \"start_date\":missing_prediction\n",
    "})], axis=0).reset_index(drop=True)\n",
    "forecast[[\"start_station_code\", \"end_station_code\", \"latitude\", \"longitude\", \"cluster\"]] = forecast[[\"start_station_code\", \"end_station_code\", \"latitude\", \"longitude\", \"cluster\"]].fillna(method=\"ffill\")\n",
    "forecast[[\"num_trips\", \"avg_duration\", \"is_member_ratio\"]] = forecast[[\"num_trips\", \"avg_duration\", \"is_member_ratio\"]].fillna(0)\n",
    "forecast.sort_values(\"start_date\", inplace=True)\n",
    "forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db369ac",
   "metadata": {},
   "source": [
    "**Feature Engineering**\n",
    "<br>\n",
    "Create feature ride frequency per route, dropping low category because the model will prone to predict 0 for those entries, and make the training faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5eb53c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_labels = [\"low\", \"medium\", \"high\"] # low: average daily ride less than 1, medium: between 1-2, high: > 2\n",
    "trip_numbers = train.groupby([\"start_station_code\", \"end_station_code\"])[\"num_trips\"].sum().reset_index()\n",
    "trip_numbers[\"route_freq\"] = \"low\"\n",
    "trip_numbers.loc[trip_numbers.num_trips > 750, \"route_freq\"] = \"medium\"\n",
    "trip_numbers.loc[trip_numbers.num_trips > 1500, \"route_freq\"] = \"high\"\n",
    "trip_numbers.drop(\"num_trips\", inplace=True, axis=1)\n",
    "trip_numbers = trip_numbers.loc[trip_numbers.route_freq != \"low\"] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c881110c",
   "metadata": {},
   "source": [
    "Create feature for the average length of the ride, the purpose is to capture travel behavior, longer might mean leisure ride."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c2a651bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "route_length = [\"1\", \"2\", \"3\", \"4\"] #higher the longer\n",
    "trip_length = pd.qcut(train.groupby([\"start_station_code\", \"end_station_code\"])[\"avg_duration\"].mean(), q=4, labels=route_length).reset_index()\n",
    "trip_length.columns = [\"start_station_code\", \"end_station_code\", \"route_length\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "05ea92a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(trip_numbers, on=[\"start_station_code\", \"end_station_code\"])\n",
    "train = train.merge(trip_length, on=[\"start_station_code\", \"end_station_code\"])\n",
    "\n",
    "test = test.merge(trip_numbers, on=[\"start_station_code\", \"end_station_code\"])\n",
    "test = test.merge(trip_length, on=[\"start_station_code\", \"end_station_code\"])\n",
    "\n",
    "forecast = forecast.merge(trip_numbers, on=[\"start_station_code\", \"end_station_code\"])\n",
    "forecast = forecast.merge(trip_length, on=[\"start_station_code\", \"end_station_code\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b8e19e",
   "metadata": {},
   "source": [
    "**Feature Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ac5a7ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(dataframe, is_train=False, categories=None):\n",
    "    \n",
    "    X_train = dataframe[[\"start_date\", \"cluster\", \"route_freq\", \"route_length\"]].copy()\n",
    "    y_train = dataframe[\"num_trips\"]\n",
    "\n",
    "    X_train[\"year\"] = X_train.start_date.dt.year\n",
    "    X_train[\"month\"] = X_train.start_date.dt.month\n",
    "    X_train[\"day_of_week\"] = X_train.start_date.dt.day_of_week\n",
    "    X_train.drop(\"start_date\", axis=1, inplace=True)\n",
    "    \n",
    "    if is_train:\n",
    "        X_train = X_train.astype(\"category\")\n",
    "        categories = {\n",
    "                    col: list(X_train[col].cat.categories)\n",
    "                    for col in X_train.columns\n",
    "                }\n",
    "        X_train_ohe = pd.get_dummies(X_train, drop_first=True)\n",
    "        return X_train_ohe, y_train, categories\n",
    "    \n",
    "    for k, v in categories.items():\n",
    "        X_train[k] = X_train[k].astype(CategoricalDtype(categories=v))    \n",
    "        X_train_ohe = pd.get_dummies(X_train, drop_first=True)\n",
    "    return X_train_ohe, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "13e2e93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ohe, y_train, categories = feature_selection(train, is_train=True)\n",
    "X_test_ohe, y_test = feature_selection(test, is_train=False, categories=categories)\n",
    "X_forecast_ohe, y_forecast = feature_selection(forecast, is_train=False, categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2a38cbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explained_variance:  0.2126\n",
      "mean_squared_log_error:  0.1798\n",
      "r2:  0.2052\n",
      "MAE:  1.3244\n",
      "MSE:  3.6534\n",
      "RMSE:  1.9114\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBRegressor(objective ='reg:squarederror', n_estimators = 100)\n",
    "model.fit(X_train_ohe,y_train)\n",
    "y_true = y_test.values\n",
    "y_pred = model.predict(X_test_ohe.values)\n",
    "regression_results(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4e486cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explained_variance:  -0.0344\n",
      "mean_squared_log_error:  0.8616\n",
      "r2:  -0.6602\n",
      "MAE:  2.1365\n",
      "MSE:  6.3697\n",
      "RMSE:  2.5238\n"
     ]
    }
   ],
   "source": [
    "y_true = y_forecast.values\n",
    "y_pred = model.predict(X_forecast_ohe.values)\n",
    "regression_results(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0228737",
   "metadata": {},
   "source": [
    "Daily forcast for the required period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "33646fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3.7380257, 4.096277 , 4.2426906, 4.1975923, 3.8962386, 2.8493266,\n",
       "        2.826318 ], dtype=float32),\n",
       " array([0., 6., 0., 2., 3., 3., 1.]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred, y_true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98dd2793",
   "metadata": {},
   "source": [
    "# Training and CV Pipeline (DID NOT RUN)\n",
    "we can add as many as models to the pipeline as we want, need three components, (model name, model object, hyperparamers search space) <br>\n",
    "for illustration purpose, I only set the iteration to 1, for better prediction performance, please select more iterations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8a915a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "models = []\n",
    "models.append(('LR', Ridge(), {'alpha': (0.01, 1.0, 'uniform')}))\n",
    "models.append(('RF', RandomForestRegressor(), {\n",
    "                            'n_estimators': (50, 100),        \n",
    "                            'min_samples_leaf': (0, 10),\n",
    "                            'min_samples_split': (0, 10),\n",
    "                            'max_depth': (0, 50)})\n",
    "                ) # Ensemble method - collection of many decision trees\n",
    "models.append(('XGB', xgb.XGBRegressor(\n",
    "                            n_jobs = 1,\n",
    "                            objective = 'reg:squarederror',\n",
    "                            eval_metric = 'rmse',\n",
    "                            tree_method='approx'\n",
    "                            ),{\n",
    "                            'learning_rate': (0.01, 1.0, 'log-uniform'),\n",
    "                            'min_child_weight': (0, 10),\n",
    "                            'max_depth': (0, 50),\n",
    "                            'max_delta_step': (0, 20),\n",
    "                            'subsample': (0.01, 1.0, 'uniform'),\n",
    "                            'colsample_bytree': (0.01, 1.0, 'uniform'),\n",
    "                            'colsample_bylevel': (0.01, 1.0, 'uniform'),\n",
    "                            'reg_lambda': (1e-9, 1000, 'log-uniform'),\n",
    "                            'reg_alpha': (1e-9, 1.0, 'log-uniform'),\n",
    "                            'gamma': (1e-9, 0.5, 'log-uniform'),\n",
    "                            'min_child_weight': (0, 5),\n",
    "                            'n_estimators': (50, 100),\n",
    "                            'scale_pos_weight': (1e-6, 500, 'log-uniform')\n",
    "                        }\n",
    "              ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ae3610",
   "metadata": {},
   "outputs": [],
   "source": [
    "def status_print(optim_result):\n",
    "    \"\"\"Status callback durring bayesian hyperparameter search\"\"\"\n",
    "    \n",
    "    all_models = pd.DataFrame(bayes_cv_tuner.cv_results_)    \n",
    "    \n",
    "    # Get current parameters and the best parameters    \n",
    "    best_params = pd.Series(bayes_cv_tuner.best_params_)\n",
    "    print('Model #{}\\nBest rmse: {}\\nBest params: {}\\n'.format(\n",
    "        len(all_models),\n",
    "        np.round(bayes_cv_tuner.best_score_, 4),\n",
    "        bayes_cv_tuner.best_params_\n",
    "    ))\n",
    "    \n",
    "    # Save all model results\n",
    "    clf_name = bayes_cv_tuner.estimator.__class__.__name__\n",
    "    all_models.to_csv(f\"{TMP_PATH}/{clf_name}_cv_results.csv\")\n",
    "\n",
    "\n",
    "for name, model, search in models: \n",
    "    bayes_cv_tuner = BayesSearchCV(\n",
    "        estimator = model,\n",
    "        search_spaces = search,    \n",
    "        scoring = 'neg_root_mean_squared_error',\n",
    "        cv = TimeSeriesSplit(n_splits=3),\n",
    "        n_jobs = 4,\n",
    "        n_iter = ITERATIONS,   \n",
    "        verbose = 0,\n",
    "        refit = True,\n",
    "        random_state = 42\n",
    "    )\n",
    "    result = bayes_cv_tuner.fit(X_train_ohe.values, y_train.values, callback=status_print)\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef4c1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in results: \n",
    "    y_true = y_test.values\n",
    "    y_pred = model.predict(X_test_ohe.values)\n",
    "    regression_results(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70906ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in results: \n",
    "    y_true = y_forecast.values\n",
    "    y_pred = model.predict(X_forecast_ohe.values)\n",
    "    regression_results(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4ac11f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
